{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b0298ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/angela/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/angela/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/angela/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m lemmatizer \u001b[38;5;241m=\u001b[39m WordNetLemmatizer()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_lg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/angela_10/lib/python3.10/site-packages/spacy/__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     31\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     38\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/angela_10/lib/python3.10/site-packages/spacy/util.py:439\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ca41c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR=\"../data\"\n",
    "SCHOOL=\"stanford\"\n",
    "SUBJECT=\"opinions\"\n",
    "START_YEAR=2010\n",
    "FINAL_YEAR=2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "187720ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCovDispersion(wv):\n",
    "    N = len(wv)\n",
    "    cov = np.cov(wv)\n",
    "    return (N, \n",
    "            np.trace(cov)/N, \n",
    "            np.linalg.norm(cov, ord=1)/N, \n",
    "            np.linalg.norm(cov, ord=2)/N, \n",
    "            np.linalg.norm(cov, ord=np.inf)/N, \n",
    "            )\n",
    "\n",
    "def cosine_distance(a, b):\n",
    "    \"\"\"Calculate the cosine distance between two numpy arrays.\n",
    "    \n",
    "    Parameters:\n",
    "    a (numpy array): First input array.\n",
    "    b (numpy array): Second input array.\n",
    "    \n",
    "    Returns:\n",
    "    float: Cosine distance between a and b.\n",
    "    \"\"\"\n",
    "    # Calculate dot product and magnitudes of the input arrays\n",
    "    dot = np.dot(a, b)\n",
    "    a_mag = np.linalg.norm(a)\n",
    "    b_mag = np.linalg.norm(b)\n",
    "    \n",
    "    # Calculate and return the cosine distance\n",
    "    return 1 - (dot / (a_mag * b_mag))\n",
    "\n",
    "def getPairwiseDispersion(wv, measure):\n",
    "    if len(wv) <= 1: return 0.0\n",
    "    distance = 0.0\n",
    "    vec = wv[0]\n",
    "    for v in wv[1:]:\n",
    "        distance += measure(vec, v)\n",
    "        # print(f\"\\tcos_distance: {measure(vec, v)}\")\n",
    "    return distance + getPairwiseDispersion(wv[1:], measure)\n",
    "\n",
    "def getNormalizedPairwiseDispersion(wv, measure):\n",
    "    '''Normalize the dispersion by (N-Choose-2) number of pairs'''\n",
    "    N = len(wv)\n",
    "    return getPairwiseDispersion(wv, measure) / (N * (N-1)/2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be3b959d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diversity',\n",
       " 'equity',\n",
       " 'inclusion',\n",
       " 'inclusive',\n",
       " 'inclusivity',\n",
       " 'equality',\n",
       " 'equal opportunity',\n",
       " 'social justice',\n",
       " 'racial justice',\n",
       " 'multi-cultural',\n",
       " 'multicultural',\n",
       " 'intercultural',\n",
       " 'intersectional',\n",
       " 'intersectionality',\n",
       " 'anti-discrimination']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diversity_words = [\n",
    "    'diversity', \n",
    "    'equity',\n",
    "    'inclusion',\n",
    "    'inclusive',\n",
    "    'inclusivity',\n",
    "    'equality', \n",
    "    'equal opportunity',\n",
    "    'social justice',\n",
    "    'racial justice', \n",
    "    'multi-cultural', \n",
    "    'multicultural',\n",
    "    'intercultural',\n",
    "    'intersectional',\n",
    "    'intersectionality',\n",
    "    'anti-discrimination'\n",
    "]\n",
    "diversity_lemmas = [lemmatizer.lemmatize(w) for w in diversity_words]\n",
    "diversity_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2a87b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diversity_pattern = \"\\b\" + \"|\".join(diversity_lemmas) + \"\\b\"\n",
    "text = \"This is an inclusive and multi-cultural center that focuses on equality and racial justice.\"\n",
    "len(re.findall(diversity_pattern, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf698d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words('english')\n",
    "def prepText(text_series):\n",
    "    '''Clean & prep text (numpy.Series): lowercase, lemmatize, stopword'''\n",
    "    text_series = text_series.apply(\n",
    "        lambda x: \" \".join(lemmatizer.lemmatize(w.lower()) for w in x.split() \n",
    "                           if w not in english_stopwords))\n",
    "    total_diversity_words = sum([len(re.findall(diversity_pattern, text)) \n",
    "                                 for text in text_series])\n",
    "    return text_series, total_diversity_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0e348f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'START_YEAR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mSTART_YEAR\u001b[49m, FINAL_YEAR\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      3\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSCHOOL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSUBJECT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody_prepped\u001b[39m\u001b[38;5;124m'\u001b[39m], num_diversity_words \u001b[38;5;241m=\u001b[39m prepText(df\u001b[38;5;241m.\u001b[39mbody)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'START_YEAR' is not defined"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for year in range(START_YEAR, FINAL_YEAR+1):\n",
    "    df = pd.read_parquet(f\"{OUTPUT_DIR}/{SCHOOL}-{SUBJECT}-{year}.parquet\")\n",
    "\n",
    "    df['body_prepped'], num_diversity_words = prepText(df.body)\n",
    "    wv = [nlp(s) for s in df['body_prepped']]\n",
    "    docmatrix = np.array([v.vector for v in wv])\n",
    "    \n",
    "    cov = getCovDispersion(docmatrix)\n",
    "    pairwise = getNormalizedPairwiseDispersion(docmatrix, cosine_distance)\n",
    "    result = {'year':     year,\n",
    "              'pairwise': pairwise,\n",
    "              'size':     cov[0],\n",
    "              'trace':    cov[1],\n",
    "              'norm-1':   cov[2], \n",
    "              'norm-2':   cov[3], \n",
    "              'norm-inf': cov[4], \n",
    "              'diversity-words': num_diversity_words,\n",
    "              'mentions-norm'  : num_diversity_words/cov[0]\n",
    "              }\n",
    "    results.append(result)\n",
    "    print(f\"{year}, {cov[0]}, {pairwise}\")\n",
    "\n",
    "# results_df = pd.DataFrame(columns=SCHEMA.keys()).astype(SCHEMA)\n",
    "results_df = pd.DataFrame.from_records(results)\n",
    "results_df.set_index('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dcccd7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linregress\n\u001b[0;32m----> 4\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mresults_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpairwise\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Calculate the linear regression\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "\n",
    "x = results_df['year']\n",
    "y = results_df['pairwise']\n",
    "\n",
    "# Calculate the linear regression\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "\n",
    "# Create a line plot of the data\n",
    "results_df.plot(x=\"year\", y=\"pairwise\", kind=\"scatter\")\n",
    "\n",
    "# Add the linear regression line to the plot\n",
    "plt.plot(x, intercept + slope*x, 'b:', label='fitted regression')\n",
    "\n",
    "plt.title(\"Stanford Daily: Opinions by year\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim(min(y)*0.95, max(y)*1.05)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03f98d30",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmentions-norm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpairwise\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm-1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm-2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm-inf\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create a figure with subplots\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(columns), ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, sharex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m16\u001b[39m))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Loop through the columns and plot each one\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ax, column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(axs, columns):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Select the data for the current column\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Select the columns to plot\n",
    "columns = [\"mentions-norm\", \"pairwise\", \"trace\", \"norm-1\", \"norm-2\", \"norm-inf\"]\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axs = plt.subplots(nrows=len(columns), ncols=1, sharex=True, figsize=(8,16))\n",
    "\n",
    "# Loop through the columns and plot each one\n",
    "for ax, column in zip(axs, columns):\n",
    "    # Select the data for the current column\n",
    "    x = range(len(results_df.index))\n",
    "    y = results_df[column]\n",
    "     \n",
    "    # Calculate the linear regression\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "    \n",
    "    print(\"{} slope:{:.5f}, int:{:.5f}, r:{:.5f}, p:{:.5f}, se:{:.5f}, x:{}\".format(\n",
    "            column, slope, intercept, r_value, p_value, std_err, x))\n",
    "\n",
    "    # Plot the data and the linear regression line\n",
    "    results_df[column].plot(ax=ax, style=\".\", x=x, y=y, label=column)\n",
    "    ax.plot(x, intercept + slope*x, 'b:', label='regression')\n",
    "    ax.set_ylim(0, max(y)*1.2)\n",
    "    \n",
    "    # Add a legend\n",
    "    ax.legend(loc='lower center')\n",
    "\n",
    "    # Add x-label for the years\n",
    "    ax.set_xticks(results_df.index)\n",
    "    ax.set_xticklabels(results_df.year)\n",
    "\n",
    "    # Add a title\n",
    "    # ax.set_title(f\"Trending of {column} in Stanford Daily\")\n",
    "    \n",
    "plt.xlabel(\"Year\")\n",
    "plt.suptitle(\"Trending of Stanford Daily opinions on Diversity metrics\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae62ae",
   "metadata": {},
   "source": [
    "## Graphs for our paper writeup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8ad5092",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmentions-norm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpairwise\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create a figure with subplots\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(columns), sharex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Loop through the columns and plot each one\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ax, column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(axs, columns):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Select the data for the current column\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Select the columns to plot\n",
    "columns = [\"mentions-norm\", \"pairwise\"]\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axs = plt.subplots(nrows=1, ncols=len(columns), sharex=True, figsize=(16,4))\n",
    "\n",
    "# Loop through the columns and plot each one\n",
    "for ax, column in zip(axs, columns):\n",
    "    # Select the data for the current column\n",
    "    x = range(len(results_df.index))\n",
    "    y = results_df[column]\n",
    "     \n",
    "    # Calculate the linear regression\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "    \n",
    "    print(\"{} slope:{:.5f}, int:{:.5f}, r:{:.5f}, p:{:.5f}, se:{:.5f}, x:{}\".format(\n",
    "            column, slope, intercept, r_value, p_value, std_err, x))\n",
    "\n",
    "    # Plot the data and the linear regression line\n",
    "    results_df[column].plot(ax=ax, style=\".\", x=x, y=y, label=column)\n",
    "    ax.plot(x, intercept + slope*x, 'b:', label='regression')\n",
    "    ax.set_ylim(0, max(y)*1.2)\n",
    "    \n",
    "    # Add a legend\n",
    "    ax.legend(loc='lower center')\n",
    "\n",
    "    # Add x-label for the years\n",
    "    ax.set_xticks(results_df.index)\n",
    "    ax.set_xticklabels(results_df.year)\n",
    "\n",
    "    # Add a title\n",
    "    # ax.set_title(f\"Trending of {column} in Stanford Daily\")\n",
    "    \n",
    "plt.xlabel(\"Year\")\n",
    "plt.suptitle(\"Trending of Stanford Daily opinions on Diversity metrics\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96473e02",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      4\u001b[0m BIPARTISAN_URL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.thebipartisanpress.com/api/endpoints/beta/robert\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# for year in range(START_YEAR, FINAL_YEAR+1):\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     df = pd.read_parquet(f\"{OUTPUT_DIR}/{SCHOOL}-{SUBJECT}-{year}.parquet\")\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df2022 \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2022\u001b[39m]\n\u001b[1;32m     11\u001b[0m articles_list \u001b[38;5;241m=\u001b[39m df2022[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m article \u001b[38;5;129;01min\u001b[39;00m articles_list:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "BIPARTISAN_API_KEY = \"gAAAAABeVpQJKRM5BqPX91XW2AKfz8pJosk182maAweJcm5ORAkkBFj__d2feG4H5KIeOKFyhUVSY_uGImiaSBCwy2L6nWxx4g==\"\n",
    "BIPARTISAN_URL = \"https://api.thebipartisanpress.com/api/endpoints/beta/robert\"\n",
    "\n",
    "\n",
    "# for year in range(START_YEAR, FINAL_YEAR+1):\n",
    "#     df = pd.read_parquet(f\"{OUTPUT_DIR}/{SCHOOL}-{SUBJECT}-{year}.parquet\")\n",
    "    \n",
    "df2022 = df[df['year'] == 2022]\n",
    "articles_list = df2022['body'].to_list()\n",
    "for article in articles_list:\n",
    "    payload = {\"API\": BIPARTISAN_API_KEY, \"Text\": article.encode(\"utf-8\")}\n",
    "    response = requests.post(BIPARTISAN_URL, data=payload)\n",
    "    print(response.text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89804873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88861d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "c21ac38248faf28f2c9521adbe733be2f0389d69400e829bbbab439e1682721f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
